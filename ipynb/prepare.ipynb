{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare reads and database\n",
    "\n",
    "Before we can cluster our reads into Amplicon Sequence Variants (ASVs) or Operational Taxonomical Units (OTUs) we have to prepare a few things. First, we have to remove the primer sequences from the reads. Second, we have to download the taxonomic database.\n",
    "\n",
    "**Note** that the following code is run in shell, not in R. Shell (bash) is a command-line program which is usually run through a terminal, and is the common interface for working with servers and computing clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [Look at reads](#reads)\n",
    "* [Remove primers](#primers)\n",
    "* [Taxonomic database](#tax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at reads<a class=\"anchor\" id=\"reads\"></a>\n",
    "We have 2 samples as an example dataset in a directory called Seqs. For each sample we have two fastq files, one for the forward reads (_1), and one for the reverse reads (_2).\n",
    "\n",
    "`ls` lists the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 275M\r\n",
      "-rw-r--r-- 1 russel mibi 72M Feb 21 00:19 SRX2198605_1.fastq\r\n",
      "-rw-r--r-- 1 russel mibi 72M Feb 21 00:19 SRX2198605_2.fastq\r\n",
      "-rw-r--r-- 1 russel mibi 32M Feb 21 00:19 SRX2198606_1.fastq\r\n",
      "-rw-r--r-- 1 russel mibi 32M Feb 21 00:19 SRX2198606_2.fastq\r\n"
     ]
    }
   ],
   "source": [
    "ls -lh Seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each read is spread across 4 lines in the fastq file. \n",
    "\n",
    "* First line: Begins with @ thereafter name of read (header for the sequence)\n",
    "* Second line: Sequence of the read\n",
    "* Third line: Begins with + and thereafter name of read (header for the quality)\n",
    "* Fourth line: Quality of read\n",
    "\n",
    "Let's look at the first read in the SRX2198608_1.fastq file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRX2198605.1\r\n",
      "GTAGTGCCAGCCGCCGCGGTAATACGTAGGTTCCGAGCGTTATTCGGATTTACTGGGCGTAAAGCGCACGCAGGCGGTTATTTAAGTCTGGTGTTAAAGCCTCTGGCTTAACCTTGGTATTCTTTTTCAGCTTTTTTACTTAGATGCCTTTAGGGAGGGGTAGATTTCCTCGTTTACCGGTGAATTCCTTAGTGTATTGGGGGAATACCGTAGGCGAAGCCGGCCTCTTGGTTATGTCCTGACGTTCCTTT\r\n",
      "+SRX2198605.1\r\n",
      "A1>AABDDFBAAEEGEECEGGCHFHA1AF/111AA//A/BE//2D00//B1F2D@1//EE?/AG1E//>EE?ECFGGGG/1BB2>BG22B010?/222F1?10111?<F11<F111?<11>111=1101<111111-.00<0<000000000;B.C?-C-;.9B0;09000.....00.---.:0////;//9//////;-;-@--///-9;9-/99>@-----9-;B///:-/;////////-----9//\r\n"
     ]
    }
   ],
   "source": [
    "head -n4 Seqs/SRX2198605_1.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality scores are [encoded](https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove primers<a class=\"anchor\" id=\"primers\"></a>\n",
    "First step of preparation is to remove the primers from the sequences, as these give problems in the downstream analysis. Furthermore, if we cannot find the primer sequence in a read it is likely noisy and should be removed. Luckly there is a tool which does all this for us, cutadapt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make a directory where we will put our trimmed reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir Seqs/Trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make a text file which contains our sample names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls Seqs | grep \"\\.fastq$\" | sed 's/_[1,2].fastq//' | sort | uniq > samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRX2198605\r\n",
      "SRX2198606\r\n"
     ]
    }
   ],
   "source": [
    "cat samples.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loop through sample names and remove primers from the reads for each sample\n",
    "* The sequence after -g is the forward primer\n",
    "* The sequence after -G is the reverse primer\n",
    "* --discard-untrimmed tells the software to remove reads if the primer was not found\n",
    "* The rest tells the software where to save the trimmed reads, and where to find the raw reads\n",
    "\n",
    "The output gives detailed information on how many reads were kept and where it found the primers in the reads. Here we save the output report in a file called cutadapt_SAMPLE.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in $(cat samples.txt)\n",
    "    do cutadapt -g GTGCCAGCMGCCGCGGTAA -G GGACTACHVGGGTWTCTAAT --discard-untrimmed \\\n",
    "        -o Seqs/Trimmed/${i}_1.fastq \\\n",
    "        -p Seqs/Trimmed/${i}_2.fastq Seqs/${i}_1.fastq Seqs/${i}_2.fastq > cutadapt_${i}.log \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomic database<a class=\"anchor\" id=\"tax\"></a>\n",
    "For assigning a taxonomy to our sequence data later we need to download and prepare a taxonomic database. There are [many different ones](https://benjjneb.github.io/dada2/training.html), but here we will use [GTDB](https://www.nature.com/articles/nbt.4229). Remember to always check if a newer version has been published.\n",
    "\n",
    "First we download the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-21 01:21:19--  https://zenodo.org/record/3266798/files/GTDB_bac120_arc122_ssu_r89.fa.gz\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.95.95\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.95.95|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7522880 (7.2M) [application/octet-stream]\n",
      "Saving to: ‘GTDB_bac120_arc122_ssu_r89.fa.gz’\n",
      "\n",
      "GTDB_bac120_arc122_ 100%[===================>]   7.17M  19.3MB/s    in 0.4s    \n",
      "\n",
      "2020-02-21 01:21:20 (19.3 MB/s) - ‘GTDB_bac120_arc122_ssu_r89.fa.gz’ saved [7522880/7522880]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget https://zenodo.org/record/3266798/files/GTDB_bac120_arc122_ssu_r89.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trim the database with same primers\n",
    "We trim the database with the primers so we only have the 16S rRNA gene region that was amplified in our samples, as the database contains the full length 16S rRNA gene sequences. Here we do not have read pairs as above, so we tell the software to look for the forward primer, then an unknown sequences (...), and then the reverse complement of the reverse primer. Only the sequence between the primers (...) will be saved.\n",
    "\n",
    "The sequences removed will also indicate which bacteria/archaea that would not be targeted by our primers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutadapt -g GTGCCAGCMGCCGCGGTAA...ATTAGAWACCCBDGTAGTCC \\\n",
    "    -o gtdb_trim.fa.gz GTDB_bac120_arc122_ssu_r89.fa.gz --discard-untrimmed > cutadapt_gtdb.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the top of the cutadapt report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 1.18 with Python 2.7.16\r\n",
      "Command line parameters: -g GTGCCAGCMGCCGCGGTAA...ATTAGAWACCCBDGTAGTCC -o gtdb_trim.fa.gz GTDB_bac120_arc122_ssu_r89.fa.gz --discard-untrimmed\r\n",
      "Processing reads on 1 core in single-end mode ...\r\n",
      "Finished in 2.16 s (118 us/read; 0.51 M reads/minute).\r\n",
      "\r\n",
      "=== Summary ===\r\n",
      "\r\n",
      "Total reads processed:                  18,333\r\n",
      "Reads with adapters:                     8,469 (46.2%)\r\n",
      "Reads written (passing filters):         8,469 (46.2%)\r\n"
     ]
    }
   ],
   "source": [
    "head cutadapt_gtdb.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 46.2% of the 16S rRNA gene sequences in the database contained our primers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is just a fasta file with sequences and names with the taxonomic assignments (it is compressed, which is why we run `gzip -dc` to look at it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Archaea;Halobacterota;Archaeoglobi;Archaeoglobales;Archaeoglobaceae;Archaeoglobus_C;Archaeoglobus_C_veneficus(RS_GCF_000194625.1)\r\n",
      "TACCGGCGGCCCGAGTGGCGGCCACTCTTATTGGGCCTAAAGCGTCCGTAGCCGGTCTGGTAAGTCCCCCGGGAAATCTGGCGGCTTAACCGTCAGACTGCCGGGGGATACTGCCAGACTAGGGACCGGGAGAGGCCGAGGGTATTCCCGGGGTAGGGGTGAAATCCTGTAATCCCGGGAGGACCACCTGTGGCGAAGGCGCTCGGCTGGAACGGGTCCGACGGTGAGGGACGAAGGCCTGGGGAGCGAACCGG\r\n",
      ">Archaea;Halobacterota;Halobacteria;Halobacteriales;Haloferacaceae;Halorubrum;Halorubrum_sp002286985(RS_GCF_002286985.1)\r\n",
      "TACCGGCAGCCCGAGTGATGGCCGATAATATTGGGCCTAAAGCGTCCGTACCTGGCCGCGCAAGTCCATCCCAAAATCCACCCGCCCAACGGGTGGGCGTCCGGTGGAAACTGCGTGGCTTGGGACCGGAAGGCGCGACGGGTACGTCCGGGGTAGGAGTGAAATCCCGTAATCCTGGACGGACCGCCGATGGCGAAAGCACGTCGCGAGGACGGATCCGACAGTGAGGGACGAAAGCCAGGGTCTCGAACCGG\r\n",
      ">Archaea;Halobacterota;Halobacteria;Halobacteriales;Halobacteriaceae;Halobacterium;Halobacterium_hubeiense(RS_GCF_001488575.1)\r\n",
      "TACCGGCAGCCCGAGTGATGGCCGATATTATTGGGCCTAAAGCGTCCGTAGCTGGCCGGACAAGTCCGTTGGGAAATCTGTTCGCTTAACGAGCAGGCGTCCAGCGGAAACTGTTCGGCTTGGGACCGGAAGACCTGAGGGGTACGTCCGGGGTAGGAGTGAAATCCTGTAATCCTGGACGGACCACCGGTGGCGAAAGCGCCTCAGGAGGACGGATCCGACAGTGAGGGACGAAAGCTAGGGTCTCGAACCGG\r\n",
      ">Archaea;Halobacterota;Halobacteria;Halobacteriales;Natrialbaceae;Halovivax;Halovivax_asiaticus(RS_GCF_000337515.1)\r\n",
      "TACCGGCAGCACGAGTGATGACCGCTATTATTGGGCCTAAAGCGTCCGTAGCCGGCCGGGCAAGTCCATCGGGAAATCCGCACGCCTAACGTGCGGGCGTCCGGTGGAAACTGCTTGGCTTGGGACCGGAAGATCCAGAGGGTACGTCTGGGGTAGGAGTGAAATCCTGTAATCCTGGACGGACCACCGGTGGCGAAAGCGCTCTGGAAAGACGGATCCGACGGTGAGGGACGAAAGCTTGGGTCACGAACCGG\r\n",
      ">Archaea;Thermoplasmatota;Thermoplasmata;Thermoplasmatales;Thermoplasmataceae;Ferroplasma;Ferroplasma_acidiphilum(RS_GCF_002078355.1)\r\n",
      "CACCCGCAGCACGAGTAGTGGTCACTTTTATTGAGCCTAAAGCGTTCGTAGCCGGTTTTGTAAATCTTCAGATAAAGCCTGAAGCTTAACTCCAGAAAGTCTGAAGAGACTGCAAGACTTGAGATCGGGTGAGGTTAAACGTACTTTCAGGGTAGGGGTAAAATCCTGTAATCCCGGAAGGACGACCAGTGGCGAAAGCGTTTAACTAGAACGAATCTGACGGTAAGGAACGAAGGCTAGGGTAGCAAACCGG\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "gzip -dc gtdb_trim.fa.gz | head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
